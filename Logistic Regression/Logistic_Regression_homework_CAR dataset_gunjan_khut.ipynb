{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Single Neuran of a Neural Network\n",
    "\n",
    "Welcome to your first programming assignment! You will build a logistic regression classifier to recognize  cats. This assignment will step you through how to do this with a Neural Network mindset where logistic regression represents a single nueron. \n",
    "\n",
    "**Instructions:**\n",
    "- Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.\n",
    "\n",
    "**You will learn to:**\n",
    "- Build the general architecture of a learning algorithm, including:\n",
    "    - Initializing parameters\n",
    "    - Calculating the cost function and its gradient\n",
    "    - Using an optimization algorithm (gradient descent) \n",
    "- Gather all three functions above into a main model function, in the right order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 -  Loading Packages ##\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Utility functions to convert images into datasets ##\n",
    "The following functions are used to convert the cats and dogs images in the dataset folder into the numpy array format with labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Load data set ###\n",
    "Use the utility functions provided above to load the train_set_x,train_set_y, test_set_x, test_set_y.\n",
    "Set the `num_px` to 64 and keep the `test_size` as the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the num_pix to 64\n",
    "num_px = 64\n",
    "PATH = \"D:\\Semester 3\\AI & Deep Learning Framework\\Assignments\\Assignment 1\\car_dataset.hdf5\"\n",
    "def load_dataset(PATH):\n",
    "    # open dataset \n",
    "    dataset_db = h5py.File(PATH, \"r\")   \n",
    "    \n",
    "    datasets = {}\n",
    "    for dataset in [\"train\", \"dev\", \"test\"]:\n",
    "        \n",
    "        # load the train set feautres (picture)\n",
    "        datasets[dataset] = {'X' : np.array(dataset_db[dataset + \"_img\"][:]),  # dataset features\n",
    "                              'Y' : np.array(dataset_db[dataset + \"_labels\"][:]) # dataset labels\n",
    "                            }\n",
    "    return datasets\n",
    "\n",
    "# Code for splitting the data to train and test data\n",
    "def create_train_test_data(datasets):\n",
    "    X_train = datasets['train']['X']\n",
    "    X_test = datasets['test']['X']\n",
    "    y_train = datasets['train']['Y']\n",
    "    y_test = datasets['test']['Y']\n",
    "    X_dev =  datasets['dev']['X']\n",
    "    y_dev =  datasets['dev']['Y']\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_dev, y_dev\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    }
   ],
   "source": [
    "datasets=load_dataset(\"D:\\Semester 3\\AI & Deep Learning Framework\\Assignments\\Assignment 1\\car_dataset.hdf5\")\n",
    "X_train, X_test, y_train, y_test, X_dev, y_dev =create_train_test_data(datasets)\n",
    "print(len(y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 - Print the shapes ###\n",
    "Print the shape of the following variables\n",
    "- Number of training examples: m_train\n",
    "- Number of testing examples: m_test\n",
    "- Height/Width of each image: num_px\n",
    "- train_set_x shape\n",
    "- train_set_y shape\n",
    "- test_set_x shape\n",
    "- test_set_y shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: X_train = 517\n",
      "Number of testing examples: X_test = 173\n",
      "train_set_x shape: (517, 64, 64, 3)\n",
      "train_set_y shape: (517,)\n",
      "test_set_x shape: (173, 64, 64, 3)\n",
      "test_set_y shape: (173,)\n",
      "test_dev_x shape: (172, 64, 64, 3)\n",
      "test_dev_y shape: (172,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = X_train.shape[0]\n",
    "y = X_test.shape[0]\n",
    "num_px = X_train.shape[1]\n",
    "\n",
    "print (\"Number of training examples: X_train = \" + str(X))\n",
    "print (\"Number of testing examples: X_test = \" + str(y))\n",
    "\n",
    "print (\"train_set_x shape: \" + str(X_train.shape))\n",
    "print (\"train_set_y shape: \" + str(y_train.shape))\n",
    "print (\"test_set_x shape: \" + str(X_test.shape))\n",
    "print (\"test_set_y shape: \" + str(y_test.shape))\n",
    "print (\"test_dev_x shape: \" + str(X_dev.shape))\n",
    "print (\"test_dev_y shape: \" + str(y_dev.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 - Fixing ill-shape vectors ####\n",
    "It is possible that the train_set_y and test_set_y have an ill-shape. Fix these shapes so the train_set_y and test_set_y are represented as a matrix with size (1, number of examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_y shape: (1, 517)\n",
      "test_set_y shape: (1, 173)\n",
      "dev_set_y shape: (1, 172)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set_y=np.reshape(y_train,(1,y_train.shape[0]))\n",
    "test_set_y=np.reshape(y_test,(1,y_test.shape[0]))\n",
    "dev_set_y = np.reshape(y_dev,(1,y_dev.shape[0]))\n",
    "\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"dev_set_y shape: \" + str(dev_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Flatten the data\n",
    "Reshape the training and test data sets so that each image is flattened into single vectors of shape (num_px  ∗ num_px  ∗ 3, 1). Check the shapes for train_set_x_flatten and test_set_x_flatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (12288, 517)\n",
      "train_set_y shape: (1, 517)\n",
      "test_set_x_flatten shape: (12288, 173)\n",
      "test_set_y shape: (1, 173)\n",
      "dev_set_x_flatten shape: (12288, 172)\n",
      "dev_set_y shape: (1, 172)\n",
      "sanity check after reshaping: [127 127 127 127 127]\n"
     ]
    }
   ],
   "source": [
    "train_set_x_flatten = X_train.reshape(X_train.shape[0],-1).T\n",
    "test_set_x_flatten = X_test.reshape(X_test.shape[0],-1).T\n",
    "dev_set_x_flatten = X_dev.reshape(X_dev.shape[0],-1).T\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"dev_set_x_flatten shape: \" + str(dev_set_x_flatten.shape))\n",
    "print (\"dev_set_y shape: \" + str(dev_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Standardize the data\n",
    "Divide every row of the dataset by 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x =train_set_x_flatten/255.\n",
    "test_set_x =test_set_x_flatten/255.\n",
    "dev_set_x =dev_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Implementing the Helper Functions ## \n",
    "\n",
    "### 3.1 - Sigmoid function\n",
    "Implement `sigmoid()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    " \"\"\"\n",
    " Compute the sigmoid of z\n",
    " Arguments:\n",
    " z -- A scalar or numpy array of any size.\n",
    " Return:\n",
    " s -- sigmoid(z)\n",
    " \"\"\"\n",
    "\n",
    " s = 1/(1+ np.exp(-z))\n",
    "\n",
    " return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = [0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Implement initialize_with_zeros\n",
    "Write a function that initializes initialize w as a vector of zeros and set `b` to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_with_zeros\n",
    "def initialize_with_zeros(dim):\n",
    " \"\"\"\n",
    " This function creates a vector of zeros of shape (dim, 1) for w and initialize\n",
    "\n",
    " Argument:\n",
    " dim -- size of the w vector we want (or number of parameters in this case)\n",
    "\n",
    " Returns:\n",
    " w -- initialized vector of shape (dim, 1)\n",
    " b -- initialized scalar (corresponds to the bias)\n",
    " \"\"\"\n",
    "\n",
    " w, b = np.zeros((dim,1)), 0\n",
    "\n",
    " assert(w.shape == (dim, 1))\n",
    " assert(isinstance(b, float) or isinstance(b, int))\n",
    " return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.]\n",
      " [0.]]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Forward propagation\n",
    "\n",
    "Implement forward propagation to calculate $A$ and cost.\n",
    "\n",
    "Forward Propagation:\n",
    "- You get X\n",
    "- You compute $A = \\sigma(w^T X + b) = (a^{(0)}, a^{(1)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- You calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Backward propagation\n",
    "\n",
    "Implement backward propagation to compute gradients $dw$ and $db$\n",
    "Here are the two formulas you will be using: \n",
    "\n",
    "$$ dw = \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ db = \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w,b,X,Y):\n",
    "    m = X.shape[1]\n",
    "\n",
    "    # forward prop\n",
    "    A = sigmoid(np.dot(np.transpose(w),X)+b)\n",
    "    cost = (-1/m)*np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))\n",
    "    \n",
    "    # backward prop\n",
    "    dw = (1/m)*np.dot(X,np.transpose(A-Y))\n",
    "    db = (1/m)*np.sum(A-Y)\n",
    "    \n",
    "    # Ensuring cost is a scalar by removing any dimensions of length 1\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    # Gradients are stored in a dictionary for use during optimization phase\n",
    "    grads = {\"dw\": dw,\n",
    "            \"db\": db}\n",
    "    \n",
    "    return grads,cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = [[0.99993216]\n",
      " [1.99980262]]\n",
      "db = 0.49993523062470574\n",
      "cost = 6.000064773192205\n"
     ]
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1], [2]]), 2, np.array([[1,2], [3,4]]), np.array([[1, 0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Optimization\n",
    "- You have initialized your parameters.\n",
    "- You are also able to compute a cost function and its gradient.\n",
    "- Now, you want to update the parameters using gradient descent.\n",
    "\n",
    "Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule\n",
    "        w = w - learning_rate * dw  # need to broadcast\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training examples\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.1124579 ]\n",
      " [0.23106775]]\n",
      "b = 1.5593049248448891\n",
      "dw = [[0.90158428]\n",
      " [1.76250842]]\n",
      "db = 0.4304620716786828\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 - Prediction\n",
    "\n",
    "Implement the `predict()` function. There is two steps to computing predictions:\n",
    "\n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector `Y_prediction`. If you wish, you can use an `if`/`else` statement in a `for` loop (though there is also a way to vectorize this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a car being present in the picture\n",
    "\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        # Convert probabilities a[0,i] to actual predictions p[0,i]\n",
    "\n",
    "        Y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "     \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Regression Model ##\n",
    "Implement the model function. Use the following notation:\n",
    "    - Y_prediction for your predictions on the test set\n",
    "    - Y_prediction_train for your predictions on the train set\n",
    "    - w, costs, grads for the outputs of optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "     # initialize parameters with zeros \n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent \n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.348325\n",
      "Cost after iteration 200: 0.293235\n",
      "Cost after iteration 300: 0.263346\n",
      "Cost after iteration 400: 0.242531\n",
      "Cost after iteration 500: 0.226353\n",
      "Cost after iteration 600: 0.213014\n",
      "Cost after iteration 700: 0.201614\n",
      "Cost after iteration 800: 0.191640\n",
      "Cost after iteration 900: 0.182771\n",
      "Cost after iteration 1000: 0.174791\n",
      "Cost after iteration 1100: 0.167547\n",
      "Cost after iteration 1200: 0.160925\n",
      "Cost after iteration 1300: 0.154839\n",
      "Cost after iteration 1400: 0.149219\n",
      "Cost after iteration 1500: 0.144009\n",
      "Cost after iteration 1600: 0.139162\n",
      "Cost after iteration 1700: 0.134640\n",
      "Cost after iteration 1800: 0.130409\n",
      "Cost after iteration 1900: 0.126441\n",
      "train accuracy: 97.48549323017409 %\n",
      "test accuracy: 89.59537572254335 %\n"
     ]
    }
   ],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the regression model function to train your model.\n",
    "### 5.1 - Setting parameters (part 1)\n",
    "Set the `num_iterations` to 5000 and `learning_rate` to 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is: [0.0005]\n",
      "train accuracy: 89.16827852998065 %\n",
      "test accuracy: 85.54913294797687 %\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.0005]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \" + str(learning_rates))\n",
    "    models = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_set accuracy: 91.86046511627907 %\n"
     ]
    }
   ],
   "source": [
    "Y_prediction_dev = predict(models['w'], models['b'], dev_set_x)\n",
    "print(\"dev_set accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_dev - dev_set_y)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot the cost function and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[\"costs\"]), label= str(models[\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Setting parameters (part 2)\n",
    "Set the `num_iterations` to 2000 and `learning_rate` to 0.005 and run the model again. Plot the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is: [0.005]\n",
      "train accuracy: 97.48549323017409 %\n",
      "test accuracy: 89.59537572254335 %\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.005]\n",
    "models1 = {}\n",
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \" + str(learning_rates))\n",
    "    models1 = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_set accuracy: 91.86046511627907 %\n"
     ]
    }
   ],
   "source": [
    "Y_prediction_dev = predict(models1['w'], models1['b'], dev_set_x)\n",
    "print(\"dev_set accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_dev - dev_set_y)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models1[\"costs\"]), label= str(models1[\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Analysis\n",
    "Compare the cost function plots of part_1 and part_2. Write your observation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Your observation here\n",
    "......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different learning rates give different costs and thus different predictions results.\n",
    "# If the learning rate is too large, the cost may oscillate up and down. It may even diverge.\n",
    "# A lower cost doesn't mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy.\n",
    "\n",
    "# In deep learning, we usually:\n",
    "# Choose the learning rate that better minimizes the cost function.\n",
    "# If our model overfits, use other techniques to reduce overfitting.\n",
    "\n",
    "# In plot 1\n",
    "# When the learning rate is: 0.0005\n",
    "# we get the training accuracy as 89.16827852998065 % and the test accuracy as 85.54913294797687 %\n",
    "# whereas \n",
    "# In plot 2\n",
    "# When the learning rate is: 0.005\n",
    "# we get the training accuracy as 97.48549323017409 % and the test accuracy as 89.59537572254335 %\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

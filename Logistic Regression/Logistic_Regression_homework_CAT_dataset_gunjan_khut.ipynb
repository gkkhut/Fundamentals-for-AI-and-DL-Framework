{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Single Neuran of a Neural Network\n",
    "\n",
    "Welcome to your first programming assignment! You will build a logistic regression classifier to recognize  cats. This assignment will step you through how to do this with a Neural Network mindset where logistic regression represents a single nueron. \n",
    "\n",
    "**Instructions:**\n",
    "- Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.\n",
    "\n",
    "**You will learn to:**\n",
    "- Build the general architecture of a learning algorithm, including:\n",
    "    - Initializing parameters\n",
    "    - Calculating the cost function and its gradient\n",
    "    - Using an optimization algorithm (gradient descent) \n",
    "- Gather all three functions above into a main model function, in the right order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 -  Loading Packages ##\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Utility functions to convert images into datasets ##\n",
    "The following functions are used to convert the cats and dogs images in the dataset folder into the numpy array format with labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_data(image, WIDTH, HEIGHT):\n",
    "    image_resized = Image.open(image).resize((WIDTH, HEIGHT))\n",
    "    image_array = np.array(image_resized).T\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(num_px,test_size=0.2):\n",
    "    cat_files = glob.glob(\"datasets/cat*\")\n",
    "\n",
    "    # Restrict cat and dog files here for testing\n",
    "    cat_list = [convert_image_to_data(i, num_px, num_px) for i in cat_files]\n",
    "    dog_list = [convert_image_to_data(i, num_px, num_px) for i in dog_files]\n",
    "\n",
    "    y_cat = np.zeros(len(cat_list))\n",
    "    y_dog = np.ones(len(dog_list))\n",
    "\n",
    "    X = np.concatenate([cat_list, dog_list])\n",
    "    y = np.concatenate([y_cat, y_dog])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Load data set ###\n",
    "Use the utility functions provided above to load the train_set_x,train_set_y, test_set_x, test_set_y.\n",
    "Set the `num_px` to 64 and keep the `test_size` as the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the num_pix to 64\n",
    "num_px = 64\n",
    "PATH = \"D:\\Semester 3\\AI & Deep Learning Framework\\Assignments\\Assignment 1\\ex1_logistic Regression_assignment\\ex1_logistic Regression_assignment\\datasets\"\n",
    "def load_dataset(PATH):\n",
    "    # open dataset \n",
    "    dataset_db = h5py.File(PATH, \"r\")\n",
    "    \n",
    "    \n",
    "    datasets = {}\n",
    "    for dataset in [\"train\", \"dev\", \"test\"]:\n",
    "        \n",
    "        # load the train set feautres (picture)\n",
    "        datasets[dataset] = {'X' : np.array(dataset_db[dataset + \"_img\"][:]),  # dataset features\n",
    "                              'Y' : np.array(dataset_db[dataset + \"_labels\"][:]) # dataset labels\n",
    "                            }\n",
    "    return datasets\n",
    "\n",
    "# Code for image conversion to a vector\n",
    "def convert_image_to_data(image, WIDTH, HEIGHT):\n",
    "    image_resized = Image.open(image).resize((WIDTH, HEIGHT))\n",
    "    image_array = np.array(image_resized).T\n",
    "    return image_array\n",
    "\n",
    "# Code for splitting the data to train and test data\n",
    "def create_train_test_data(num_px,test_size=0.2):\n",
    "    cat_files = glob.glob(\"D:\\Semester 3\\AI & Deep Learning Framework\\Assignments\\Assignment 1\\ex1_logistic Regression_assignment\\ex1_logistic Regression_assignment\\datasets\\cat*\")\n",
    "    dog_files = glob.glob(\"D:\\Semester 3\\AI & Deep Learning Framework\\Assignments\\Assignment 1\\ex1_logistic Regression_assignment\\ex1_logistic Regression_assignment\\datasets\\dog*\")\n",
    "\n",
    "    # Restrict cat and dog files here for testing\n",
    "    cat_list = [convert_image_to_data(i, num_px, num_px) for i in cat_files]\n",
    "    dog_list = [convert_image_to_data(i, num_px, num_px) for i in dog_files]\n",
    "\n",
    "    y_cat = np.zeros(len(cat_list))\n",
    "    y_dog = np.ones(len(dog_list))\n",
    "\n",
    "    X = np.concatenate([cat_list, dog_list])\n",
    "    y = np.concatenate([y_cat, y_dog])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "cat_files = glob.glob(\"D:\\Semester 3\\AI & Deep Learning Framework\\Assignments\\Assignment 1\\ex1_logistic Regression_assignment\\ex1_logistic Regression_assignment\\datasets\\cat*\")\n",
    "dog_files = glob.glob(\"datasets/dog*\")\n",
    "\n",
    "print (len(cat_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 - Print the shapes ###\n",
    "Print the shape of the following variables\n",
    "- Number of training examples: m_train\n",
    "- Number of testing examples: m_test\n",
    "- Height/Width of each image: num_px\n",
    "- train_set_x shape\n",
    "- train_set_y shape\n",
    "- test_set_x shape\n",
    "- test_set_y shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: X_train = 640\n",
      "Number of testing examples: X_test = 160\n",
      "train_set_x shape: (640, 3, 64, 64)\n",
      "train_set_y shape: (640,)\n",
      "test_set_x shape: (160, 3, 64, 64)\n",
      "test_set_y shape: (160,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=create_train_test_data(64,test_size=0.2)\n",
    "X = X_train.shape[0]\n",
    "y = X_test.shape[0]\n",
    "num_px = X_train.shape[1]\n",
    "\n",
    "print (\"Number of training examples: X_train = \" + str(X))\n",
    "print (\"Number of testing examples: X_test = \" + str(y))\n",
    "\n",
    "print (\"train_set_x shape: \" + str(X_train.shape))\n",
    "print (\"train_set_y shape: \" + str(y_train.shape))\n",
    "print (\"test_set_x shape: \" + str(X_test.shape))\n",
    "print (\"test_set_y shape: \" + str(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 - Fixing ill-shape vectors ####\n",
    "It is possible that the train_set_y and test_set_y have an ill-shape. Fix these shapes so the train_set_y and test_set_y are represented as a matrix with size (1, number of examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_y shape: (1, 640)\n",
      "test_set_y shape: (1, 160)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=create_train_test_data(64,test_size=0.2)\n",
    "train_set_y=np.reshape(y_train,(1,y_train.shape[0]))\n",
    "test_set_y=np.reshape(y_test,(1,y_test.shape[0]))\n",
    "\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Flatten the data\n",
    "Reshape the training and test data sets so that each image is flattened into single vectors of shape (num_px  ∗ num_px  ∗ 3, 1). Check the shapes for train_set_x_flatten and test_set_x_flatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (12288, 640)\n",
      "train_set_y shape: (1, 640)\n",
      "test_set_x_flatten shape: (12288, 160)\n",
      "test_set_y shape: (1, 160)\n",
      "sanity check after reshaping: [ 97 103  94  89  81]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set_x_flatten = X_train.reshape(X_train.shape[0],-1).T\n",
    "test_set_x_flatten = X_test.reshape(X_test.shape[0],-1).T\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Standardize the data\n",
    "Divide every row of the dataset by 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x =train_set_x_flatten/255.\n",
    "test_set_x =test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Implementing the Helper Functions ## \n",
    "\n",
    "### 3.1 - Sigmoid function\n",
    "Implement `sigmoid()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    " \"\"\"\n",
    " Compute the sigmoid of z\n",
    " Arguments:\n",
    " z -- A scalar or numpy array of any size.\n",
    " Return:\n",
    " s -- sigmoid(z)\n",
    " \"\"\"\n",
    "\n",
    " s = 1/(1+ np.exp(-z))\n",
    "\n",
    " return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = [0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Implement initialize_with_zeros\n",
    "Write a function that initializes initialize w as a vector of zeros and set `b` to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_with_zeros\n",
    "def initialize_with_zeros(dim):\n",
    " \"\"\"\n",
    " This function creates a vector of zeros of shape (dim, 1) for w and initialize\n",
    "\n",
    " Argument:\n",
    " dim -- size of the w vector we want (or number of parameters in this case)\n",
    "\n",
    " Returns:\n",
    " w -- initialized vector of shape (dim, 1)\n",
    " b -- initialized scalar (corresponds to the bias)\n",
    " \"\"\"\n",
    "\n",
    " w, b = np.zeros((dim,1)), 0\n",
    " \n",
    " assert(w.shape == (dim, 1))\n",
    " assert(isinstance(b, float) or isinstance(b, int))\n",
    " return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.]\n",
      " [0.]]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Forward propagation\n",
    "\n",
    "Implement forward propagation to calculate $A$ and cost.\n",
    "\n",
    "Forward Propagation:\n",
    "- You get X\n",
    "- You compute $A = \\sigma(w^T X + b) = (a^{(0)}, a^{(1)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- You calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Backward propagation\n",
    "\n",
    "Implement backward propagation to compute gradients $dw$ and $db$\n",
    "Here are the two formulas you will be using: \n",
    "\n",
    "$$ dw = \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ db = \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w,b,X,Y):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # forward prop\n",
    "    A = sigmoid(np.dot(np.transpose(w),X)+b)\n",
    "    cost = (-1/m)*np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))\n",
    "    \n",
    "    # back prop\n",
    "    dw = (1/m)*np.dot(X,np.transpose(A-Y))\n",
    "    db = (1/m)*np.sum(A-Y)\n",
    "    # Ensuring cost is a scalar by removing any dimensions of length 1\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    # Gradients are stored in a dictionary for use during optimization phase\n",
    "    grads = {\"dw\": dw,\n",
    "            \"db\": db}\n",
    "    \n",
    "    return grads,cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = [[0.99993216]\n",
      " [1.99980262]]\n",
      "db = 0.49993523062470574\n",
      "cost = 6.000064773192205\n"
     ]
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1], [2]]), 2, np.array([[1,2], [3,4]]), np.array([[1, 0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Optimization\n",
    "- You have initialized your parameters.\n",
    "- You are also able to compute a cost function and its gradient.\n",
    "- Now, you want to update the parameters using gradient descent.\n",
    "\n",
    "Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule \n",
    "        w = w - learning_rate * dw  # need to broadcast\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training examples\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.1124579 ]\n",
      " [0.23106775]]\n",
      "b = 1.5593049248448891\n",
      "dw = [[0.90158428]\n",
      " [1.76250842]]\n",
      "db = 0.4304620716786828\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 - Prediction\n",
    "\n",
    "Implement the `predict()` function. There is two steps to computing predictions:\n",
    "\n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector `Y_prediction`. If you wish, you can use an `if`/`else` statement in a `for` loop (though there is also a way to vectorize this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        # Convert probabilities a[0,i] to actual predictions p[0,i]\n",
    "\n",
    "        Y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Regression Model ##\n",
    "Implement the model function. Use the following notation:\n",
    "    - Y_prediction for your predictions on the test set\n",
    "    - Y_prediction_train for your predictions on the train set\n",
    "    - w, costs, grads for the outputs of optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize parameters with zeros\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.835387\n",
      "Cost after iteration 200: 0.791591\n",
      "Cost after iteration 300: 0.753244\n",
      "Cost after iteration 400: 0.717081\n",
      "Cost after iteration 500: 0.682776\n",
      "Cost after iteration 600: 0.650456\n",
      "Cost after iteration 700: 0.620043\n",
      "Cost after iteration 800: 0.591323\n",
      "Cost after iteration 900: 0.564055\n",
      "Cost after iteration 1000: 0.538031\n",
      "Cost after iteration 1100: 0.513085\n",
      "Cost after iteration 1200: 0.489088\n",
      "Cost after iteration 1300: 0.465942\n",
      "Cost after iteration 1400: 0.443566\n",
      "Cost after iteration 1500: 0.421892\n",
      "Cost after iteration 1600: 0.400859\n",
      "Cost after iteration 1700: 0.380414\n",
      "Cost after iteration 1800: 0.360521\n",
      "Cost after iteration 1900: 0.341180\n",
      "train accuracy: 91.25 %\n",
      "test accuracy: 60.0 %\n"
     ]
    }
   ],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the regression model function to train your model.\n",
    "### 5.1 - Setting parameters (part 1)\n",
    "Set the `num_iterations` to 5000 and `learning_rate` to 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is: 0.0005\n",
      "train accuracy: 80.78125 %\n",
      "test accuracy: 64.375 %\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.0005]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \" + str(i))\n",
    "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 5000, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:40%\"> \n",
    "    \n",
    "    <tr>\n",
    "        <td> **Train Accuracy**  </td> \n",
    "        <td> 91.25 % </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>**Test Accuracy** </td> \n",
    "        <td> 60.0 % </td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot the cost function and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl4VdW9//H3NzMQppCBEAJhCKPMAWRQERFQFJyogrX6s9ehLVq9t7dV29622lqtVut0nafrhLMgVQEVlEGEAIIQpsiUEJIAAQlTxvX74xz0GAMJkJOd4fN6njzJ3mfvfb5bD/lkr7X22uacQ0RE5HhCvC5ARETqPoWFiIhUSWEhIiJVUliIiEiVFBYiIlIlhYWIiFRJYSEiIlVSWIiISJUUFiIiUqWwYB7czMYDDwGhwDPOuXsqvP4gcLZ/sSkQ75xr5X/tauAP/tf+6px78XjvFRsb61JSUmqwehGRhm/58uW7nXNxVW1nwZruw8xCgY3AuUA2sAyY4pzLOMb2NwEDnHPXmlkMkA6kAQ5YDgxyzu091vulpaW59PT0Gj4LEZGGzcyWO+fSqtoumM1QQ4BM59xm51wxMB2YdJztpwCv+X8eB8x1zhX4A2IuMD6ItYqIyHEEMyySgKyA5Wz/uh8xs45AJ+DTE91XRESCL5hhYZWsO1ab1xXAW865shPZ18yuN7N0M0vftWvXSZYpIiJVCWYHdzaQHLDcHsg5xrZXAL+qsO+oCvvOr7iTc+4p4Cnw9VmcfKnSEBUXF5OZmcnhw4e9LqXOaNKkCV27diUiIsLrUqSeCWZYLANSzawTsANfIEytuJGZdQdaA18ErJ4N3G1mrf3LY4Hbg1irNECZmZmEhYWRmJiIWWUXq42Lc44DBw6wceNGevfurf8mckKC1gzlnCsFpuH7xb8OeMM5t9bM7jSziQGbTgGmu4BhWc65AuAufIGzDLjTv06k2g4fPkx0dLR+KfqZGdHR0Rw5coRZs2ZRWlrqdUlSjwT1Pgvn3AfABxXW/U+F5T8fY9/ngOeCVpw0CgqKHzIzzIyMjAwSExNJS6tyxKQIoDu4+fZQCQ99vInV2fu8LkWk1kRFRbF7926vy5B6pNGHhYXAgx9vZMEm/cORmjdv3jxGjhzJ8OHDeeSRR370elFRETfccAPDhw9nwoQJZGV9P2L8kUceYfjw4YwcOZL58+dXecxbbrmFoUOHMmbMGMaMGcOaNWuOWZeZEawbcqVhCmozVH3QIiqcxJZRZOYf8LoUaWDKysq44447mD59OomJiZx//vmMGzeObt26fbfNa6+9RqtWrVi8eDHvvfcef/3rX3nyySfZuHEjM2bMYN68eeTl5XH55ZezcOFCgOMe849//CMXXHCBJ+crDVujv7IASE1ozsa8Qq/LkAZm5cqVpKSk0LFjRyIiIpg0aRKzZ8/+wTazZ89m8uTJAFxwwQUsXLgQ5xyzZ89m0qRJREZG0qFDB1JSUli5cmW1jikSDI3+ygIgNT6aLzfvoazcERqiDtGG6MHPsti0q2bvt0iNa8KtZyUf8/Xc3FzatWv33XJiYiIrVqw45jZhYWG0aNGCgoICdu7cyaBBg36wb25uLsBxj3nPPffw4IMPMnLkSO644w4iIyNP7SRF/HRlAXRLiKaotJzsvYe8LkUakMr6BCqOzjrWNie6HuD2229nwYIFfPDBB+zbt4/HHnvsZEsX+RFdWeBrhgLYmHeAjm2aeVyNBMPxrgCCJTExkZyc7yct2LlzJ23btq10m3bt2lFaWsr+/ftp3bo17dq1+9G+CQkJAMc85tHXIyMjufzyy3niiSeCdm7S+OjKAl8zFKB+C6lR/fv3Z8uWLWzfvp3i4mJmzJjB2LFjf7DN2LFjefPNNwGYNWsWI0eOxMwYO3YsM2bMoKioiO3bt7NlyxYGDBhw3GPm5eUBvquVjz76iO7du9fuCUuDpisLoLlGREkQhIWF8be//Y2pU6dSVlbGFVdcQffu3fnHP/5Bv379GDduHFOmTOHmm29m+PDhtGrViscffxyA7t27c+GFFzJq1ChCQ0O5++67CQ0NBaj0mADTpk1jz549OOfo3bs39957r2fnLg1P0B5+VNtO9eFHP3tuKXsOFPHvm8+owarES8uXL/9BZ7D45OTksGjRIlJTUznvvPO8Lkc8VhceflSvdIuPJjP/AGXlDSM8RURqksLCL9U/IiqrQCOiREQqUlj4HR0RtUn9Fg1KQ2lmrSnOOf03kZOisPDTiKiGp0mTJhQWFuqXo59zjsLCQkpKSrwuReohjYbyOzoiapPCosHo2rUrS5cupbCwUFOV4wuLkpIStmzZQnl5OWFh+ucv1adPS4DUhOZqhmpAIiIiKCwsZPHixbRq1UqB4VdaWkpRUREdO3b0uhSpRxQWAbrFR/OS5ohqUMaMGUNERATbtm2jvLzc63LqhKZNmzJy5MgfzH4rUhWFRYDAEVEpsZr2oyEIDw/nnHPO8boMkXpPHdwBNCJKRKRyCosAGhElIlI5hUWA5lHhtNOIKBGRH1FYVNBVI6JERH5EYVGB5ogSEfkxhUUF3RKaa44oEZEKFBYVdE3wdXKrKUpE5HsKiwo0IkpE5McUFhVoRJSIyI8pLCqhEVEiIj+ksKiERkSJiPyQwqISGhElIvJDCotKHB0RpU5uEREfhUUljo6IUr+FiIiPwqISGhElIvJDCotjSE1ozsY8XVmIiIDC4phS46P5ZpdGRImIgMLimDQiSkTkewqLY0jViCgRke8ENSzMbLyZbTCzTDO77Rjb/MTMMsxsrZm9GrC+zMy+8n/NDGadlemqEVEiIt8JC9aBzSwUeAw4F8gGlpnZTOdcRsA2qcDtwAjn3F4ziw84xGHnXP9g1VeV5lHhdIhpypyMPG48qwuhIeZVKSIingvmlcUQINM5t9k5VwxMByZV2OY64DHn3F4A51x+EOs5Ybeem8qqrH08v2iL16WIiHgqmGGRBGQFLGf71wXqBnQzs0VmtsTMxge8FmVm6f71FwWxzmO6qH8So3vEc/+cDWzdfdCLEkRE6oRghkVl7TYVx6GGAanAKGAK8IyZtfK/1sE5lwZMBf5lZl1+9AZm1/sDJX3Xrl01V/n3x+fui/sQHhrCb99eTbmG0YpIIxXMsMgGkgOW2wM5lWwzwzlX4pzbAmzAFx4453L83zcD84EBFd/AOfeUcy7NOZcWFxdX82cAtG0ZxR8n9GLplgJe/nJbUN5DRKSuC2ZYLANSzayTmUUAVwAVRzW9B5wNYGax+JqlNptZazOLDFg/AsjAI5PT2nNmtzju+XC97rsQkUYpaGHhnCsFpgGzgXXAG865tWZ2p5lN9G82G9hjZhnAPOC/nXN7gJ5Aupmt8q+/J3AUVW0zM/5+SR9CzLjtndU4p+YoEWlcrKH84ktLS3Pp6elBfY9XvtzG799dw90X92Hq0A5BfS8RkdpgZsv9/cPHpTu4T8CUwR0Y1rkNd3+wjpx9h70uR0Sk1igsTkBIiHHvpX0pK3f8TqOjRKQRUVicoA5tmvKHC3qyYNNu/nd+ptfliIjUCoXFSZg6pAOT+rfjgbkbWZy52+tyRESCTmFxEo7erNc5Lpqbp68kb/8Rr0sSEQkqhcVJahYZxuNXDuRgURk3vbqS0rJyr0sSEQkahcUpSE1ozt8v6cPSrQXcN2eD1+WIiASNwuIUXTQgiSuHduDJzzYzZ22u1+WIiASFwqIG/PGCXpyW1IL/enMV2/doOhARaXgUFjUgKjyUx68chAG/eGU5h4vLvC5JRKRGKSxqSHJMUx68vD8ZO/dz6+tf6YY9EWlQFBY16JyeCfz+/J58tDaXez9a73U5IiI1JmjP4G6sfj6yE9v2HOLJzzfToU1Trhza0euSREROmcKihpkZf7qwF9l7D/E/M9aS1KoJo7rHe12WiMgpUTNUEISFhvDI1IF0S2jOtFdXsm7nfq9LEhE5JQqLIImODOO5a9JoFhnKtS8s05QgIlKvKSyCKLFlE569ejDfHi7h5y8u42BRqdcliYicFIVFkJ2W1JJHpw5g3c5Crvu/dI6U6B4MEal/FBa1YHSPBO67rC+Lv9nDr15ZQYkmHRSRekZhUUsuGdieuy46jU/W53Pr619Rppv2RKQe0dDZWnTV6R05VFTK3z9cT9OIUO65pC8hIeZ1WSIiVVJY1LIbzurCwaJSHv40k6YRYfzpwl6YKTBEpG5TWHjg1nO7cbC4jGcXbiE6MozfjOvudUkiIselsPCAmfGHCT05VFzKo/MyiQgL4eZzUr0uS0TkmBQWHjEz/npRH4pKy3lg7kaKSsv4zdjuapISkTpJYeGh0BDj/sv6ERkWwmPzvuFISTl/mNBTgSEidY7CwmMhIcbdF/chMiyUZxduoai0jDsnnqZRUiJSpygs6oCjM9VGhofw5GebKSop555L+xKqwBCROkJhUUeYGbeN70FUWCgPfbKJ4rJy/jm5H2Ghum9SRLynsKhDzIxbz+1GZHgI//hoA4eKy3hkygCiwkO9Lk1EGjn92VoH/XJUV/4ysTcfr8vjp898yb5DxV6XJCKNnMKijrp6eAqPThnI6uxvueyJL9ix77DXJYlII6awqMMm9E3kxWuHkPftES7938Wsz9UT90TEGwqLOm5Ylza8ceMwHI7JT3zBks17vC5JRBohhUU90DOxBe/8cgQJLaL42bNL+ffqnV6XJCKNjMKinkhq1YS3bhxGn/Yt+dWrK3hsXibO6ZkYIlI7FBb1SKumEbzyH0OZ2K8d983ewH++sUqPaRWRWqH7LOqZqPBQHrqiP90Sorl/zka27TnIk1elEdc80uvSRKQBC+qVhZmNN7MNZpZpZrcdY5ufmFmGma01s1cD1l9tZpv8X1cHs876xsyYNjqV/71yIBk793PRY4tYt1MjpUQkeIIWFmYWCjwGnAf0AqaYWa8K26QCtwMjnHO9gVv862OAPwFDgSHAn8ysdbBqra/O75PImzcMp7S8nMseX8zHGXlelyQiDVQwryyGAJnOuc3OuWJgOjCpwjbXAY855/YCOOfy/evHAXOdcwX+1+YC44NYa73Vp31LZk4bSZf4aK57KZ2HP9lEebk6vkWkZgUzLJKArIDlbP+6QN2Abma2yMyWmNn4E9gXM7vezNLNLH3Xrl01WHr9ktAiitevH8ZF/ZN4YO5Grn8pnW8Pl3hdlog0IMEMi8rm1674J28YkAqMAqYAz5hZq2rui3PuKedcmnMuLS4u7hTLrd+aRITywE/68ZeJvZm/YReTHl2oO75FpMYEMyyygeSA5fZATiXbzHDOlTjntgAb8IVHdfaVCsyMq4enMP360zlYXMbFjy1m5ir9ZxORUxfMsFgGpJpZJzOLAK4AZlbY5j3gbAAzi8XXLLUZmA2MNbPW/o7tsf51Ug1pKTH8+6aR9G7XgptfW8md72dQUlbudVkiUo8FLSycc6XANHy/5NcBbzjn1prZnWY20b/ZbGCPmWUA84D/ds7tcc4VAHfhC5xlwJ3+dVJN8S2iePW607lmeArPLdrC5U9q5loROXlWnSkjzGyyc+7NqtZ5KS0tzaWnp3tdRp00c1UOd7zzNaEhxn2X9WVs77ZelyQidYSZLXfOpVW1XXWvLG6v5jqpgyb2a8esm0aSHNOE619azl/eX0txqZqlRKT6jjvdh5mdB5wPJJnZwwEvtQBKg1mY1KyU2Ga8/Yvh/P2D9Ty/aCvLt+3l0SkD6dCmqdeliUg9UNWVRQ6QDhwBlgd8zcR345zUI5Fhofx5Ym+evGoQW3cfZMLDCzRaSkSqpbp9FuHOuRL/z62BZOfc6mAXdyLUZ3FisgoO8evpK1mxfR8XD0jiL5N60yIq3OuyRKSW1XSfxVwza+Gfs2kV8LyZPXBKFYqnkmOa8sYNw7hlTCozV+Vw3r8WsHSLBpyJSOWqGxYtnXP7gUuA551zg4AxwStLakNYaAi3jOnGmzcOIyzUuOKpL7hv9np1fovIj1Q3LMLMLBH4CTAriPWIBwZ2aM2/bz6DyYOSeWzeN1z6+GIy8w94XZaI1CHVDYs78d1A941zbpmZdQY2Ba8sqW3RkWHce1lfnvjpQLL2HmLCwwt4ZsFmyjSDrYhQzQ7u+kAd3DUnf/8R7nj3az5el8/glNbcd1k/UmKbeV2WiARBjXZwm1l7M3vXzPLNLM/M3jaz9qdeptRF8S2iePpnafxzcj/W5xYy/qHPeWHRFj0nQ6QRq24z1PP47q1oh++5Eu/710kDZWZcOqg9c289i9M7t+HP72cw5eklbN9zyOvSRMQD1Q2LOOfc8865Uv/XC0DjfoBEI9G2ZRTPXzOYf1zal7U5+xn3r895duEW9WWINDLVDYvdZvZTMwv1f/0U2BPMwqTuMDN+MjiZ2beeydDOMdw1K4NLHl+shyuJNCLVDYtr8Q2bzQV2ApcB/y9YRUndlNSqCc9fM5iHruhPVsEhLnh4If+cs4EjJWVelyYiQVbdsLgLuNo5F+eci8cXHn8OWlVSZ5kZk/on8fF/nsXEfu145NNMJjy8gGVbdfe3SENW3bDo65zbe3TB/yCiAcEpSeqDmGYRPHB5f168dghHSsqZ/MQX3Pb2avYeLPa6NBEJguqGRYh/AkEA/HNEHXd6c2kczuoWx5xbz+S6Mzrx5vJsznngM95ank1DuX9HRHyqGxb/BBab2V1mdiewGPhH8MqS+qRZZBi/n9CLWTeNJKVNU37z5iouf2oJm/IKvS5NRGpIte/gNrNewGjAgE+ccxnBLOxE6Q7uuqG83PFGehZ//3A9B4tKue7Mztw0uitNI3QhKlIXVfcObk33IUGx50ARf/9wPW8tz6Zdyyh+P6EX5/dpi5l5XZqIBKjp51mInJA20ZHcP7kfb944jJZNI/jVqyuY+vSXbFTTlEi9pLCQoBqcEsOsm0Zy16TeZOzcz3kPLeDO9zPYf6TE69JE5AQoLCToQkOMq4alMO83o7h8cDLPL97C6Pvn8/qy7Zo2RKSeUFhIrYlpFsHdF/fh/Wkj6dimGb97+2sufGQhSzZr5hiRuk5hIbXutKSWvHXjMB6eMoBvD5dwxVNLuPGl5ZrRVqQOU1iIJ8yMif3a8cl/ncVvxnbj8027GPPAZ/z9w3XqzxCpgxQW4qmo8FCmjU5l3m9GMbF/O578bDNn3zef//tiKyVl5V6XJyJ+CgupExJaRHH/5H68P20kqQnR/M+MtYx98HM+WrNTU4eI1AEKC6lT+rRvyWvXnc5z16QRFmLc+PIKLnviC5Zv06y2Il5SWEidY2aM7pHAh78+g3su6UNWwSEuffwLbnxpOZn5B7wuT6RR0nQfUucdKi7l6c+38NTn33C4pIzJg5L59ZhU2rVq4nVpIvWe5oaSBmfPgSIem/cNLy/ZBgZXD+vIL0d1pXWzCK9LE6m3FBbSYGXvPcS/Pt7EOyuyaRYRxvVndubakZ1oFqmZbUVOlMJCGryNeYXcP3sDczLyiGkWwS/O6sJVwzoSFR7qdWki9YbCQhqNldv38sDcjSzYtJv45pFMG92VywcnExmm0BCpisJCGp0vN+/hn3M2snRrAUmtmnDT6K5cOqg94aEa9CdyLAoLaZSccyzM3M39czayKmsfyTFNuOnsVC4emKTQEKlEnXj4kZmNN7MNZpZpZrdV8vo1ZrbLzL7yf/1HwGtlAetnBrNOaTjMjDNS43jvl8N55mdptGoSwW/fXs3of87njWVZmkJE5CQF7crCzEKBjcC5QDawDJgS+OxuM7sGSHPOTatk/wPOuejqvp+uLKQyzjnmbcjnXx9vYnX2tyTHNGHa2V25ZKCap0SgblxZDAEynXObnXPFwHRgUhDfT+RHjt4NPuNXI3jumjRaN43gd29/zaj75vPykm0UlZZ5XaJIvRDMsEgCsgKWs/3rKrrUzFab2VtmlhywPsrM0s1siZldVNkbmNn1/m3Sd+3aVYOlS0MTGBrPXzOY+BaR/OG9NZz5j3k8u3ALh4sVGiLHE8ywsErWVWzzeh9Icc71BT4GXgx4rYP/0mgq8C8z6/Kjgzn3lHMuzTmXFhcXV1N1SwNmZpzdI553fjGcV/5jKJ1im3HXrAxG3vspj8//hkI9S0OkUsEMi2wg8EqhPZATuIFzbo9zrsi/+DQwKOC1HP/3zcB8YEAQa5VGxswY0TWW6dcP480bh3FaUkvu/Wg9I+75lH/O2cCeA0VVH0SkEQlmWCwDUs2sk5lFAFcAPxjVZGaJAYsTgXX+9a3NLNL/cywwAshAJAgGp8Tw4rVDmDltBMO7xPLovExG3Pspf565lh37DntdnkidELTJdJxzpWY2DZgNhALPOefWmtmdQLpzbiZws5lNBEqBAuAa/+49gSfNrBxfoN0TOIpKJBj6tm/FE1cNIjO/kCc+28zLS7bx8pJtTOqfxC9GdaZrfHOvSxTxjG7KEzmGHfsO8/Tnm5m+bDtHSsoZ0zOBG8/qTFpKjNelidQY3cEtUkMKDhbzwuKtvPTFVvYeKmFgh1bccFYXzu2ZQEhIZeM4ROoPhYVIDTtcXMaby7N4esFmsgoO0zm2Gded2ZmLByRppluptxQWIkFSWlbOR2tzefKzzXy941vaNIvgqmEduer0jrSJjvS6PJETorAQCTLnHF9s3sMzC7bw6fp8IsNCuGRge34+shNd46s9U42Ip6obFnq0mMhJMjOGd4lleJdYMvMP8OzCLbyzIpvXlm5ndI94fj6yE8O7tMFM/RpS/+nKQqQG7TlQxMtLtvPSkq3sPlBM94TmXDsyhUn91a8hdZOaoUQ8dKSkjPdX5fDswi2szy0kplkEU4d04KphHUloEeV1eSLfUViI1AHOOZZsLuC5RVv4eF0eoWZM6JvINcNTGNChtdfliajPQqQuMDOGdWnDsC5t2LbnIC8s3sqb6dnM+CqHfu1bcs2IFM7vk6jnhUudpysLkVp2oKiUd1Zk88LirWzedZDY6AimDu3IlUM7qIlKap2aoUTquPJy3/PCX1i8lXkb8gk1Y9xpbbnq9I4M7RSjUVRSK9QMJVLHhYQYZ3aL48xucWzdfZCXl2zjjfQs/r16J90TmvPTYR25eEAS0ZH6Zyre05WFSB1yuNg3iur/lmxlzY79REeGcenAJK48vSPdEjTrrdQ8NUOJ1GPOOVZm7ePlL7Yxa/VOisvKGdIphiuHdmD8aW3VIS41RmEh0kAUHCzmzfQsXl26nW17DtGmWQST05K5cmgHkmOael2e1HMKC5EG5miH+MtLtvHxujwccEZqHFOHJHNOzwTCQ4P54EtpqBQWIg3Yzm8PM31pFm+kZ7Hz2yPENY/kJ2ntuWKwrjbkxCgsRBqB0rJy5m/YxWtLtzNvQ76uNuSEKSxEGpmcfYd5fVkWry/LInf/EWKjI7h0YHsuH5xM5zhNmS6VU1iINFJl5Y7PN/quNj5Zn09ZuWNIpxiuGJzMeacl0iRCI6nkewoLESG/8AhvL9/B68u2s3XPIZpHhTGxXzt+kpZM3/YtdZe4KCxE5HtHZ799Iz2LD77eSVFpOT3aNmdyWjIXD0giplmE1yWKRxQWIlKp/UdKeH9VDm8sy2JV9reEhxrn9kpg8qBkzkiNJUyd4o2KwkJEqrQ+dz9vLMvmva92UHCwmPjmkVw8MInJg9rTNV7TizQGCgsRqbbi0nI+XZ/PW8uzmbfB1yneP7kVlw1qz4V929GyabjXJUqQKCxE5KTsKizivZU7eHN5FhvzDhARFsK5PRO4dFASZ6bGqZmqgVFYiMgpcc6xZsd+3l6RzYyvdrD3UAmx0ZFc1L8dlw5qT8/EFl6XKDVAYSEiNaa4tJz5G/J5e0U2n67Pp6TM0aNtcy4d2J5J/dsRryf81VsKCxEJioKDxcxancM7K3bwVdY+QgxGdI3lkoFJjOvdlqYRelhTfaKwEJGg+2bXAd5buYN3V+4ge+9hmkaEMr53WyYNSGJElzbq36gHFBYiUmvKyx3p2/by7sps/r16J/uPlBIbHcmF/RK5eEASfZJ0t3hdpbAQEU8UlZYxb/0u3lu5g0/X51NcVk7n2GZM6p/EpP7tSIlt5nWJEkBhISKe+/ZQCR+u2cm7K3fw5ZYCAPolt2Jiv3Zc2DdRHeN1gMJCROqUnH2HmbU6hxlf5bA2Zz8hBsO6tGFSP1/HuG7884bCQkTqrMz8QmZ+lcOMVTls23OIiNAQzuwWx8T+7RjTM14jqmqRwkJE6jznHKuzv2Xmqhxmrc4hb38RTcJDGdMrgQv7JnJW9zgiw/T8jWBSWIhIvVJe7li6tYD3V+Xwwdc72XuohOaRYZzbO4EL+7ZjRNdYIsI0FLem1YmwMLPxwENAKPCMc+6eCq9fA9wH7PCvetQ594z/tauBP/jX/9U59+Lx3kthIdJwlJSVsyhzN7NW72T22lwKj5TSskk443u35YJ+iQzrrHs4aornYWFmocBG4FwgG1gGTHHOZQRscw2Q5pybVmHfGCAdSAMcsBwY5Jzbe6z3U1iINExFpWUs2LibWatzmJuRx8HiMmKaRTD+tLZM6JPI0E4xCo5TUN2wCGYv0hAg0zm32V/QdGASkHHcvXzGAXOdcwX+fecC44HXglSriNRRkWG+PowxvRI4UlLG/A35/PvrXN5buYNXv9xOm8Dg6NyG0BDd/BcMwQyLJCArYDkbGFrJdpea2Zn4rkJudc5lHWPfpGAVKiL1Q1R4KONPS2T8aYkcLvYFx6yvd/LOih288uV2YqMjGNtbVxzBEMywqCzeK7Z5vQ+85pwrMrMbgReB0dXcFzO7HrgeoEOHDqdWrYjUK00iQjmvTyLn9UnkUHEp89bv4oM1O3l3he+KI6ZZBON6J3B+n0RO79yGcAXHKQlmWGQDyQHL7YGcwA2cc3sCFp8G7g3Yd1SFfedXfAPn3FPAU+DrszjVgkWkfmoaEcaEvolM6Ou74vhsYz4ffJ3LzK9yeG1pFq2ahnNuzwTO69OWEV1jNRz3JASzgzsMX9PSOfhGOy0Dpjrn1gZsk+ic2+n/+WLgd8650/0d3MuBgf5NV+Dr4C441vupg1tEKjpSUsbnG3fx0Zpc5q7Lo/BIKc0jwxjdM57zTmvLWd3iaRKeD9FCAAAJFklEQVTRuIPD8w5u51ypmU0DZuMbOvucc26tmd0JpDvnZgI3m9lEoBQoAK7x71tgZnfhCxiAO48XFCIilYkKD2Vs77aM7d2W4tJyFn2zm4++zmVORi4zvsqhSXgoo7rHMf60tpzdI54WUZpy5Fh0U56INDqlZeUs3VLAh2tymb02l/zCIsJDjRFdYxnfuy1jeiUQGx3pdZm1wvP7LGqbwkJETkZ5uWNl1j5mr83lozW5bC84RIhBWscYxvZOYFzvtiTHNPW6zKBRWIiInCDnHOt2FvLR2lzmrM1lfW4hAL0SW3wXHD3aNm9QD3JSWIiInKKtuw8yJyOXOWvzWL59L85BckwTxvZqy9heCQzq2Lre38uhsBARqUH5hUf4OCOfuRm5LMrcQ3FZOa2bhnNOzwTG9krgjNS4ejmySmEhIhIkB4pK+WzDLuZm5PLJ+nwKj5QSFR7CyK5xnNsrntE9EohrXj86yBUWIiK1oKSsnC83FzA3I5eP1+WzY99hzGBAcivO7dWWc3sl0CWuWZ3t51BYiIjUMuccGTv3Mzcjj4/X5bFmx34AOsU245we8YzplUBaHevnUFiIiHgsZ99hPlmXx8fr8vniG18/R8sm4ZzdPY5zeiZwVvc4z28EVFiIiNQhB4pKWbhpF3Mz8pm3IZ+Cg8WEhRhDOsUwukc8Y3omkBLbrNbrUliIiNRRZeWOldv38sn6fD5Zl8fGvAMAdI5rxpieCZzdPZ60lNa1MlOuwkJEpJ7IKjjEJ+vy+GR9Pks276GkzNE8KoyzusUxukc8o7rHE9MsIijvrbAQEamHfM1Vu/l0fR7zNuxiV2HRd6OrRveI5+we8fRKbFFjo6sUFiIi9Vx5uWNNzrd8uj6fT9fnszr7WwASWkRydndfcIzoGkt05MlPIK6wEBFpYHYVFjF/g6+DfMHG3RQWlRIeaozr3ZZHpw6s+gCV8Px5FiIiUrPimkcyOS2ZyWnJlJSVk751L/M25BMeGvwb/hQWIiL1UHhoCMO6tGFYlza18n515zZCERGpsxQWIiJSJYWFiIhUSWEhIiJVUliIiEiVFBYiIlIlhYWIiFRJYSEiIlVqMNN9mNkuYNspHCIW2F1D5dQnOu/GRefduFTnvDs65+KqOlCDCYtTZWbp1ZkfpaHReTcuOu/GpSbPW81QIiJSJYWFiIhUSWHxvae8LsAjOu/GRefduNTYeavPQkREqqQrCxERqVKjDwszG29mG8ws08xu87qeYDKz58ws38zWBKyLMbO5ZrbJ/721lzXWNDNLNrN5ZrbOzNaa2a/96xv6eUeZ2VIzW+U/77/413cysy/95/26mUV4XWswmFmoma00s1n+5cZy3lvN7Gsz+8rM0v3rauSz3qjDwsxCgceA84BewBQz6+VtVUH1AjC+wrrbgE+cc6nAJ/7lhqQU+C/nXE/gdOBX/v/HDf28i4DRzrl+QH9gvJmdDtwLPOg/773Azz2sMZh+DawLWG4s5w1wtnOuf8CQ2Rr5rDfqsACGAJnOuc3OuWJgOjDJ45qCxjn3OVBQYfUk4EX/zy8CF9VqUUHmnNvpnFvh/7kQ3y+QJBr+eTvn3AH/Yrj/ywGjgbf86xvceQOYWXtgAvCMf9loBOd9HDXyWW/sYZEEZAUsZ/vXNSYJzrmd4PvFCsR7XE/QmFkKMAD4kkZw3v6mmK+AfGAu8A2wzzlX6t+koX7e/wX8Fij3L7ehcZw3+P4gmGNmy83sev+6GvmsN/ZncFf2lHMND2uAzCwaeBu4xTm33/fHZsPmnCsD+ptZK+BdoGdlm9VuVcFlZhcA+c655WY26ujqSjZtUOcdYIRzLsfM4oG5Zra+pg7c2K8ssoHkgOX2QI5HtXglz8wSAfzf8z2up8aZWTi+oHjFOfeOf3WDP++jnHP7gPn4+mxamdnRPxIb4ud9BDDRzLbia1Yeje9Ko6GfNwDOuRz/93x8fyAMoYY+6409LJYBqf6REhHAFcBMj2uqbTOBq/0/Xw3M8LCWGudvr34WWOeceyDgpYZ+3nH+KwrMrAkwBl9/zTzgMv9mDe68nXO3O+faO+dS8P17/tQ5dyUN/LwBzKyZmTU/+jMwFlhDDX3WG/1NeWZ2Pr6/PEKB55xzf/O4pKAxs9eAUfhmoswD/gS8B7wBdAC2A5OdcxU7westMxsJLAC+5vs27Dvw9Vs05PPui68zMxTfH4VvOOfuNLPO+P7ijgFWAj91zhV5V2nw+JuhfuOcu6AxnLf/HN/1L4YBrzrn/mZmbaiBz3qjDwsREalaY2+GEhGRalBYiIhIlRQWIiJSJYWFiIhUSWEhIiJVUliI+JnZYv/3FDObWsPHvqOy9xKpLzR0VqSCwPH5J7BPqH96jWO9fsA5F10T9Yl4QVcWIn5mdnSW1nuAM/zPBLjVPyHffWa2zMxWm9kN/u1H+Z+V8Sq+m/4ws/f8k7itPTqRm5ndAzTxH++VwPcyn/vMbI3/OQSXBxx7vpm9ZWbrzewV/93omNk9Zpbhr+X+2vxvJI1XY59IUKQytxFwZeH/pf+tc26wmUUCi8xsjn/bIcBpzrkt/uVrnXMF/ik2lpnZ286528xsmnOufyXvdQm+5030w3dn/TIz+9z/2gCgN755jBYBI8wsA7gY6OGcc0en9BAJNl1ZiFRtLPAz/3TfX+Kb8jrV/9rSgKAAuNnMVgFL8E1SmcrxjQRec86VOefygM+AwQHHznbOlQNfASnAfuAI8IyZXQIcOuWzE6kGhYVI1Qy4yf/0sf7OuU7OuaNXFge/28jX1zEGGOZ/Qt1KIKoaxz6WwLmLyoAw/zMZhuCbRfci4KMTOhORk6SwEPmxQqB5wPJs4Bf+qc4xs27+WT0ragnsdc4dMrMe+KYEP6rk6P4VfA5c7u8XiQPOBJYeqzD/czlaOuc+AG7B14QlEnTqsxD5sdVAqb856QXgIXxNQCv8ncy7qPzRlB8BN5rZamADvqaoo54CVpvZCv+U2Ue9CwwDVuF7IM9vnXO5/rCpTHNghplF4bsqufXkTlHkxGjorIiIVEnNUCIiUiWFhYiIVElhISIiVVJYiIhIlRQWIiJSJYWFiIhUSWEhIiJVUliIiEiV/j8vXMz1S6TnPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Setting parameters (part 2)\n",
    "Set the `num_iterations` to 2000 and `learning_rate` to 0.005 and run the model again. Plot the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is: 0.005\n",
      "train accuracy: 91.25 %\n",
      "test accuracy: 60.0 %\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.005]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \" + str(i))\n",
    "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Analysis\n",
    "Compare the cost function plots of part_1 and part_2. Write your observation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Your observation here\n",
    "......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different learning rates give different costs and thus different predictions results.\n",
    "# If the learning rate is too large, the cost may oscillate up and down. It may even diverge.\n",
    "# A lower cost doesn't mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy.\n",
    "\n",
    "# In deep learning, we usually:\n",
    "# Choose the learning rate that better minimizes the cost function.\n",
    "# If our model overfits, use other techniques to reduce overfitting.\n",
    "\n",
    "# In plot 1\n",
    "# When the learning rate is: 0.0005\n",
    "# we get the training accuracy as 80.78125 % and the test accuracy as 64.375 %\n",
    "# whereas \n",
    "# In plot 2\n",
    "# When the learning rate is: 0.005\n",
    "# we get the training accuracy as 91.25 % and the test accuracy as 60 %\n",
    "\n",
    "# Thus we conclude that here reducing the learning rate gives better result\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
